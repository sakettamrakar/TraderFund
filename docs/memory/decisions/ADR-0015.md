# ADR-0015: Bounded Automation Contract

**Status**: Accepted
**Date**: 2026-01-24
**Context**: Automation is dangerous. Unchecked feedback loops can destroy capital or state in seconds. We need a way to introduce automation safey.

## Decision

The system operates under a **Bounded Automation Contract**.

- **Phase 6 Rule**: Automation is **Passive Only** (Monitor/Suggest).
- **Prohibitions**: Monitors CANNOT write to business data, mute alerts, delete files, or call external APIs.
- **Graduation**: Moving from Passive to Active requires strictly defined "Graduation Criteria" (Sustained accuracy, specific Governance Authorization).

## Rationale

- **Safety**: "Suggest, Don't Act" prevents runaway automation failures.
- **Trust**: We must observe the "ghost in the machine" before giving it keys.
- **Reversibility**: Passive monitors can be ignored; active automators must be fought.

## Alternatives

- **Full Automation**: Let the bot fix things. Rejected (high risk).
- **No Automation**: Humans do everything. Rejected (unscalable).
- **Sandboxed Execution**: Virtual machines. Rejected (too complex for now).

## Consequences

- ** toil**: Humans must still perform the actions suggested by monitors.
- **Latency**: Response to issues is bounded by human reaction time.
- **Discipline**: Requires humans to actually look at the logs/suggestions.

## Evidence

- `docs/epistemic/ledger/decisions.md`: D008
- `docs/epistemic/bounded_automation_contract.md`
